\chapter{Generative Diffeomorphic Deformation Model}

This section discusses the general architecture of our model. In a first step, we examine the brain registration model proposed in \cite{voxelmorph} and discuss its applicability to the generative brain aging problem. We then detail our modifications to this model and the motivations

Diffeomorphic transformations are differentiable and invertible and therefore topology preserving
diffeomorphism: what is it, why do we want it?

diffeomorphism, resulting in an invertible and therefore topology preserving 

\section{Voxelmorph}
In medical imaging, deformable image registration tackles the problem of warping one image onto another. More formally, given two scans $x$ and $y$, the aim is to find a deformation function $\Phi$ such that $\Phi \circ x$ is similar to $y$.
Dalca et al propose a deep learning architecture
%based on the concept of a Variational Autoencoder (VAE)
to learn such a mapping for 3-dimensional MRI brain data. Specifically, given $x$ and $y$ the model generates a stationary velocity field $v$ which defines the deformation ${\Phi : \R^3 \rightarrow \R^3}$ mapping $x$ to $y$ through the ordinary differential equation (ODE)
\begin{equation} \label{eq:ODE}
	\frac{\partial \Phi^{(t)}}{\partial t} = v(\Phi^{(t)})
\end{equation}

where $\Phi^{(0)} = id$ is the identity transformation and t is time.
The final deformation field $\Phi^{(1)}$ is then obtained by integrating the field $v$ over time $t = [0, 1]$ which is computed numerically using the scaling and squaring method.\\
In group theory, $v$ is a member of the Lie algebra and is exponentiated to produce $\Phi^{(1)} = \exp(v)$.
The collection $\{\Phi^{(t)}\}_{t \in [0,1]}$ forms a one-parameter subgroup of diffeomorphisms and therefore for any scalars $t$ and $t'$ we have 
\begin{equation}
	\exp((t + t')v) = \exp(tv) \circ \exp(t'v)
\end{equation}

where $\circ$ is a composition map associated with the Lie group. Consequently, we can then use the recurrence $\Phi^{(1/2^{(t-1)})} = \Phi^{(1/2^{t})} \circ \Phi^{(1/2^{t})}$ starting from $\Phi^{(1/2^T)}$ to obtain $\Phi^{(1)} = \Phi^{(1/2)} \circ \Phi^{(1/2)}$ where $T$ is chosen such that $v \approx 0$.

The model uses a variational inference method to generate a stationary displacement field $z$ which defines the deformation $\Phi_z$ through the ODE (\ref{eq:ODE}). The prior probabilty of $z$ is modeled as
\begin{equation}
	p(z) = \mathcal{N}(z; 0, \Sigma_z)
\end{equation}

Spatial smoothness of z is is encouraged by letting ${\Sigma_z^{-1} = \Lambda_z = \lambda L}$ where $\Lambda_z$ is a precision matrix, $L$ is the Laplacian of a neighborhood graph defined as $L = D - A$, with graph degree matrix $D$ and voxel adjacency matrix $A$, and $\lambda$ denotes a parameter controlling the scale of the velocity field.

The target image $y$ is interpreted as a noisy observation of the warped image~$x$
\begin{equation}
	p(y|z;x) = \mathcal{N}(y; x \circ \Phi_z, \sigma^2 \mathbbm{I})
\end{equation}

with $\sigma^2$ reflecting the variance of the additive noise.

Finally, a likely registration field $\Phi_z$ is obtained by sampling $z$ from the posterior distribution $p(z | x; y)$. Since this distribution is intractable in this setting, we use a variational approach and introduce 

VAE

\begin{equation}
	\mathcal{L}(\psi; \bold{x}, \bold{y}) = \mathcal{L}_{rec} + \mathcal{L}_{KL} + \text{const} 
\end{equation}


\begin{equation}
	\begin{split}
		\boldsymbol{\varphi} \\
		\boldsymbol{\phi} \\
		\mathcal{L}_{rec}
		& = -\E_{q}[ \log p( \mathbf{x} | \mathbf{z}; \mathbf{y} ) ] \\[10pt]
		& = \frac{1}{2 \sigma^2 K} \mathlarger{\sum_{k}} \norm{\mathbf{x} - \mathbf{y} \circ \Phi_{z_{k}}}^{2}
	\end{split}
\end{equation}

\begin{equation}
	\begin{split}
		\mathcal{L}_{KL} & =
		\text{KL} [ q_{\psi} ( \mathbf{z} | \mathbf{x} ; \mathbf{y} ) || p ( \mathbf{z} ) ] \\[10pt]
		& = 
		\frac{1}{2} \bigg[
		\underbrace{
			tr( \lambda \mathbf{D} \Sigma_{z | x; y} - \log \abs{ \Sigma_{z | x; y} } ) \vphantom{\mu_{z | x; y}^{T}}
		}_{\text{sigma term}} +
		\underbrace{
			\mu_{z | x; y}^{T} \Lambda_{z} \mu_{z | x; y}
		}_{\text{precision term}} \bigg]
	\end{split}
\end{equation}

\begin{equation}
	\frac{\lambda}{2} \sum \sum_{j \in N(I)} ( \mu[i] - \mu[j])^{2}
\end{equation}



\begin{equation}
	\mathcal{L}_{gen} = \mathcal{L}_{D} + \mathcal{L}_{sim} + \mathcal{L}_{KL} + \mathcal{L}_{reg} + \mathcal{L}_{clf} 
\end{equation}

\begin{equation}
	\mathcal{L}_{cri} = \mathcal{L}_{D} + \mathcal{L}_{sim} + \mathcal{L}_{KL} + \mathcal{L}_{reg} + \mathcal{L}_{clf} 
\end{equation}



\section{Adaptation}
supervised vs unsupervised, 2 inputs vs 1

\subsection{Generative Adversarial Setting}
GAN vs VAE (training loss in VAE? see experiments)
smaller scale of changes

\begin{equation}
	\mathcal{L}_{GAN}(M, D) = \E _ { x \sim p_d(x | c = 0) } [ D (x) ] 
	 - \E _ { x \sim p_d(x | c = 1) } [ D (x + M(x)) ].
\end{equation}

\begin{equation}
	\mathcal{L}_{reg} (M) = \norm{M(x)}_1.
\end{equation}

\begin{equation}
	M^* = \argmin_M \max_{D \in \mathcal{D}} \mathcal{L}_{GAN}(M, D) + \lambda \mathcal{L}_{reg} (M),
\end{equation}

where $\mathcal{D}$ is the set of 1-Lipschitz functions.


Similar to \cite{VAGAN} we additionally introduce a similarity loss $\mathcal{L}_{sim}$ defined as the $L_1$ difference between the original image $x$ and the warped image $\hat{y} = x \circ \Phi$
\begin{equation}
	\mathcal{L}_{sim} = \norm{\hat{y} - x}_1
\end{equation}

Finally, we add a loss term to encourage sparseness of the velocity fields
\begin{equation}
	\mathcal{L}_{sparse} = \norm{\mu_z}_1
\end{equation}


\subsection{Arbitrary Time Step Scaling and Squaring}
maths, some plots
introduce problem of arbitrary time step
introduce solution, proof

want to learn from more than just a single time step.
scaling and squaring as described to obtain phi(1) but can be used to get also phi(1/powers2) straightforward. However, data pairs don't necessarily match. Could do iteratively (cite wegmayr) but tradeoff between small step and high accuracy/data availability vs large step and computational viability. 

\chapter{Applications}

want to predict brain after given time step
useful for diagnostics (use existing methods)
useful for understanding (different brains, same time step)

\section{Long Term Prediction}
not realistic but works to see trends

\section{Conversion Prediction}
Want to know whether patients with Mild Cognitive Impairment convert to AD patients

\section{Feature Attribution}
probabilistic model (sampling from distribution)
predict multiple images instead of just one
get heat map of changes

\chapter{Data}

\section{Synthetic Data}
Due to the difficulty of reliably validating the performance of generative models

spheres, maybe also more complex (multiple spheres, overlapping)
randomized position, delta
shows that the model understands deltas

\section{MRI Data}
For the 

\subsection{Data Sources}

ADNI + AIBL

\subsection{Data Processing}
Our data processing pipeline can be separated into three distinct steps:

\begin{itemize}
\item Extraction
\item Registration
\item Segmentation
\end{itemize}

Firstly, in what is known as brain extraction or alternatively skull stripping, we extracts the brain from the surrounding non-brain tissue and then secondly align the resulting images to a common reference atlas using linear transformations with 12 degrees of freedom. Both steps are performed using the FSL toolkit (TODO cite), using the bet and flirt commands respectively. Thirdly, we segment each voxel into three classes, White Matter (WM), Gray Matter (GM) and Cerebrospinal Fluid (CSF) while simultaneously correcting a scanner-related image artifact known as the bias field. The results of this operation are three voxel-wise probability maps for the different classes and we then proceed to subtract the WM map from the GM map while dropping the CSM map, resulting in a new image with a number of potentially benefitial properties: Firstly, all voxel values are restricted to the range [-1, 1] and can be directly compared across different images. Note that the MR imaging process captures relative intensity differences and as a consequence, direct comparison of absolute values is in general not possible for raw or even unit gaussian normalized MRI data. Furthermore, the operation enhances the structural contrast and removes low level variance in the image. We choose this apprach based on the assumption, that most of the information relevant to the brain aging process is contained in the structural changes of the segmentation (TODO experiment on data), with smaller differences in intensity most likely representing noise.
Incidentally, since the output of our preprocessing pipeline is a segmentation mask, one could combine the data from T1 scans with data from different brain imaging modalities such as T2-weighted MRI data or proton density (PD) scans, therefore drastically increasing the number of possible data sources. However, we do not validate or pursue this idea as a part of this thesis.

\subsection{Data Splitting}

different splits for different tasks
dx classifier
conversion set
leave one visit out
singles
pairs

\chapter{Experiments}

\section{Synthetic Data}
results without age reg
results with age reg? somewhat tricky

\section{VAE}

\section{Diagnosis Classifier}

\section{Age Regressor}
Validating generative outputs is hard
we use an age regressor to predict the age of a given scan
use regressor on generated image
show regressor accuracy with normal eval set
explain why this is only partially relevant
show regressor performance on LOO eval set
show that delta loss is significantly better than absolute L1 loss

\section{Fixed Delta Prediction}
predict brain after a given time step
check resulting ages from age reg
plots plots plots

\section{Long Term Prediction}
train on AD only, HC only?

\section{Conversion Prediction}
F1 score, accuracy

\chapter{Related Work}

\chapter{Discussion}
