{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii(path):\n",
    "    nii = nib.load(path)\n",
    "    vol = nii.get_data().astype(np.float32)\n",
    "    return np.squeeze(vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 18 runs \n",
      "\n",
      "0 ../runs/gan_20190428_1448_gpu=7_bs=4_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=50.0_vr=0.5_is=5_cs=5_rf=10_rs=5_sw=True_glw=[1_100_500_10_0]_clw=[1_1_10]/predict \n",
      "\n",
      "1 ../runs/gan_20190430_1720_gpu=7_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=50.0_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_glw=[1_100_500_10_0_0]_clw=[1_1_10]_tag=beefier_decoder_more_summaries_batchnorm/predict \n",
      "\n",
      "2 ../runs/gan_20190503_1139_gpu=2_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25.0_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_500.0_10.0_250.0_0.0_0.0_50.0]_clw=[1.0_1.0_10.0]_tag=new_arch/predict \n",
      "\n",
      "3 ../runs/gan_20190505_1942_gpu=7_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_100.0_10.0_100.0_0.0_0.0_25.0]_clw=[1_1_10]_tag=train_s1_eval_s2/predict \n",
      "\n",
      "4 ../runs/gan_20190505_2247_gpu=6_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=False_clf=True_glw=[1.0_100.0_10.0_100.0_0.0_0.0_100.0]_clw=[1_1_10]_tag=clf_test_run/predict \n",
      "\n",
      "5 ../runs/gan_20190506_1227_gpu=1_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=False_clf=True_glw=[1.0_100.0_10.0_100.0_0.0_0.0_25.0]_clw=[1_1_10]_tag=clf_lower_clf_loss/predict \n",
      "\n",
      "6 ../runs/gan_20190507_1210_gpu=5_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=True_glw=[1.0_200.0_5.0_100.0_0.0_0.0_25.0_25.0]_clw=[1_1_10]_tag=reg_and_clf_on_clf_train/predict \n",
      "\n",
      "7 ../runs/gan_20190510_0855_gpu=6_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_200.0_5.0_100.0_0.0_0.0_10.0]_clw=[1_1_10]_tag=AD_only/predict \n",
      "\n",
      "8 ../runs/gan_20190510_0911_gpu=4_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_200.0_5.0_100.0_0.0_0.0_10.0]_clw=[1_1_10]_tag=HC_only/predict \n",
      "\n",
      "9 ../runs/gan_20190510_1454_gpu=1_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=False_clf=True_glw=[1.0_200.0_5.0_100.0_0.0_0.0_0.0_50.0]_clw=[1_1_10]_tag=new_clf_l1_loss/predict \n",
      "\n",
      "10 ../runs/gan_20190517_0008_gpu=3_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.001_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_500.0_5.0_25.0_0.0_0.0_50.0]_clw=[1_1_10]_tag=split5_s1s3_s2s4/predict \n",
      "\n",
      "11 ../runs/gan_20190517_0825_gpu=0_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.0001_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=True_glw=[1.0_500.0_5.0_75.0_0.0_0.0_50.0_100.0]_clw=[1_1_10]/predict \n",
      "\n",
      "12 ../runs/gan_20190518_2207_gpu=0_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.0001_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_500.0_5.0_100.0_0.0_0.0_25.0]_clw=[1_1_10]_tag=split5_AD_s1s2s3s4_s0/predict \n",
      "\n",
      "13 ../runs/gan_20190518_2327_gpu=3_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.0001_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=False_glw=[1.0_500.0_5.0_100.0_0.0_0.0_25.0]_clw=[1_1_10]_tag=split5_HC_s1s2s3s4_s0/predict \n",
      "\n",
      "14 ../runs/gan_20190519_1522_gpu=0_bs=16_cl=8_lr=0.001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=False_reg=False_clf=False_glw=[1.0_200.0_5.0_50.0_0.0_0.0]_clw=[1_1_10]_tag=split5_AD_s1s2s3s4_s0/predict \n",
      "\n",
      "15 ../runs/gan_20190519_1522_gpu=3_bs=16_cl=8_lr=0.001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=False_reg=False_clf=False_glw=[1.0_200.0_5.0_50.0_0.0_0.0]_clw=[1_1_10]_tag=split5_HC_s1s2s3s4_s0/predict \n",
      "\n",
      "16 ../runs/gan_20190519_1546_gpu=2_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=True_clf=True_glw=[1.0_200.0_5.0_100.0_0.0_0.0_25.0_25.0]_clw=[1_1_10]/predict \n",
      "\n",
      "17 ../runs/gan_20190520_0906_gpu=2_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=False_clf=True_glw=[1.0_200.0_5.0_100.0_0.0_0.0_200.0]_clw=[1_1_10]/predict \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_dirs = glob.glob('../runs/*/predict')\n",
    "run_dirs = sorted(run_dirs)\n",
    "\n",
    "print('found {} runs'.format(len(run_dirs)), '\\n')\n",
    "\n",
    "for i, run in enumerate(run_dirs):\n",
    "    print(i, run, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1 pre_dirs\n",
      "0 split_test/gen_035_04\n"
     ]
    }
   ],
   "source": [
    "# set run dir\n",
    "run_dir = run_dirs[17]\n",
    "\n",
    "pre_dirs = glob.glob(os.path.join(glob.escape(run_dir), '*', '*'))\n",
    "pre_dirs = sorted(pre_dirs)\n",
    "\n",
    "print('found {} pre_dirs'.format(len(pre_dirs)))\n",
    "\n",
    "for i, pre_dir in enumerate(pre_dirs):\n",
    "    #print(i, os.path.basename(pre_dir))\n",
    "    print(i, pre_dir.split('/')[-2] + '/' + pre_dir.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found meta.csv: (271, 41)\n"
     ]
    }
   ],
   "source": [
    "# generator config, run_dir, etc...\n",
    "pre_dir = pre_dirs[0]\n",
    "\n",
    "csv_path = os.path.join(pre_dir, 'meta.csv')\n",
    "csv = pd.read_csv(csv_path)\n",
    "\n",
    "print('found meta.csv: {}'.format(csv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found model file\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "clf_dir = '../../dx/runs/clf_20190516_2031_gpu=4_bs=32_lr=0.0001_b1=0.9_b2=0.999_ep=0.01_bn=True_mp=True_lk=0.0_ls=[16_2_32_1_32_2_64_1_64_2_128_1_128_2_256_1_256_1]_tag=split5_s2s4_s1s3/'\n",
    "\n",
    "model_name = 'clf_0100'\n",
    "model_file = os.path.join(clf_dir, model_name+'.h5')\n",
    "\n",
    "if os.path.isfile(model_file):\n",
    "    print('found model file')\n",
    "else:\n",
    "    print('model file not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu config\n",
    "gpu_id = 6\n",
    "\n",
    "if gpu_id is not None:                                                     \n",
    "    gpu = '/gpu:' + str(gpu_id)                                            \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)                       \n",
    "    config = tf.ConfigProto()                                              \n",
    "    config.gpu_options.allow_growth = True                                 \n",
    "    config.allow_soft_placement = True                                     \n",
    "    set_session(tf.Session(config=config))                                 \n",
    "else:                                                                      \n",
    "    gpu = '/cpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting predict\n",
      "step 0\n",
      "step 10\n",
      "step 20\n",
      "step 30\n",
      "step 40\n",
      "step 50\n",
      "step 60\n",
      "step 70\n",
      "step 80\n",
      "step 90\n",
      "step 100\n",
      "step 110\n",
      "step 120\n",
      "step 130\n",
      "step 140\n",
      "step 150\n",
      "step 160\n",
      "step 170\n",
      "step 180\n",
      "step 190\n",
      "step 200\n",
      "step 210\n",
      "step 220\n",
      "step 230\n",
      "step 240\n",
      "step 250\n",
      "step 260\n",
      "step 270\n",
      "finished predict\n",
      "writing csv to ../runs/gan_20190520_0906_gpu=2_bs=16_cl=8_lr=0.0001_b1=0.0_b2=0.9_ep=0.1_pl=25_lk=0.2_bn=True_vr=0.5_is=6_cs=5_rf=10_rs=5_sw=True_reg=False_clf=True_glw=[1.0_200.0_5.0_100.0_0.0_0.0_200.0]_clw=[1_1_10]/predict/split_test/gen_035_04/clf_0100.csv\n"
     ]
    }
   ],
   "source": [
    "print('starting predict')\n",
    "\n",
    "with tf.device(gpu):\n",
    "    \n",
    "    # load classifier model\n",
    "    classifier = keras.models.load_model(model_file)\n",
    "    \n",
    "    for i, (_, row) in enumerate(csv.iterrows()):\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('step', i)\n",
    "        \n",
    "        xr = load_nii(row['img_path_0'])[None, ..., None]\n",
    "        yr = load_nii(row['img_path_1'])[None, ..., None]\n",
    "        yf = load_nii(row['img_path_yf'])[None, ..., None]\n",
    "        \n",
    "        batch = np.concatenate([xr, yr, yf], axis=0)\n",
    "        \n",
    "        pred = classifier.predict([batch])\n",
    "        \n",
    "        csv.loc[csv.img_id_0 == row['img_id_0'], 'pAD_xr'] = pred[0, 1]\n",
    "        csv.loc[csv.img_id_0 == row['img_id_0'], 'pAD_yr'] = pred[1, 1]\n",
    "        csv.loc[csv.img_id_0 == row['img_id_0'], 'pAD_yf'] = pred[2, 1]\n",
    "        \n",
    "print('finished predict')\n",
    "\n",
    "csv_out_path = os.path.join(pre_dir, model_name+'.csv')\n",
    "\n",
    "print('writing csv to {}'.format(csv_out_path))\n",
    "\n",
    "csv.to_csv(csv_out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 clf_0100.csv\n"
     ]
    }
   ],
   "source": [
    "clf_csvs = glob.glob(os.path.join(glob.escape(pre_dir), '[!meta]*.csv'))\n",
    "clf_csvs = sorted(clf_csvs)\n",
    "\n",
    "for i, clf_csv in enumerate(clf_csvs):\n",
    "    print(i, os.path.basename(clf_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 44)\n"
     ]
    }
   ],
   "source": [
    "csv_path = clf_csvs[0]\n",
    "csv = pd.read_csv(csv_path)\n",
    "print(csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: xr -> yr: 0.15111475044299838\n",
      "s: xr -> yf: 0.29524820302603627\n",
      "p: xr -> yr: 0.3230244012305107\n",
      "p: xr -> yf: 0.26479144197189586\n"
     ]
    }
   ],
   "source": [
    "scsv = csv[csv.pat_dx_1 == 2]\n",
    "print('s: xr -> yr:', (scsv.pAD_yr - scsv.pAD_xr).mean())\n",
    "print('s: xr -> yf:', (scsv.pAD_yf - scsv.pAD_xr).mean())\n",
    "\n",
    "pcsv = csv[csv.pat_dx_1 == 3]\n",
    "print('p: xr -> yr:', (pcsv.pAD_yr - pcsv.pAD_xr).mean())\n",
    "print('p: xr -> yf:', (pcsv.pAD_yf - pcsv.pAD_xr).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pAD_xr      0.286097\n",
      "pAD_yr      0.499379\n",
      "pAD_yf      0.570332\n",
      "pat_dx_1    2.361624\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pAD_xr</th>\n",
       "      <th>pAD_yr</th>\n",
       "      <th>pAD_yf</th>\n",
       "      <th>pat_dx_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031614</td>\n",
       "      <td>0.105626</td>\n",
       "      <td>9.934682</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.209686</td>\n",
       "      <td>90.621603</td>\n",
       "      <td>98.840255</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.695033</td>\n",
       "      <td>63.928884</td>\n",
       "      <td>95.160389</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390791</td>\n",
       "      <td>78.736687</td>\n",
       "      <td>0.609304</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010653</td>\n",
       "      <td>0.043072</td>\n",
       "      <td>0.168996</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52.519608</td>\n",
       "      <td>96.616983</td>\n",
       "      <td>50.039494</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.596059</td>\n",
       "      <td>41.218093</td>\n",
       "      <td>0.309517</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.611539</td>\n",
       "      <td>48.109752</td>\n",
       "      <td>94.421756</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99.639696</td>\n",
       "      <td>99.051291</td>\n",
       "      <td>98.386800</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.029453</td>\n",
       "      <td>0.046560</td>\n",
       "      <td>2.237074</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pAD_xr     pAD_yr     pAD_yf  pat_dx_1\n",
       "0   0.031614   0.105626   9.934682     200.0\n",
       "1   6.209686  90.621603  98.840255     200.0\n",
       "2  80.695033  63.928884  95.160389     200.0\n",
       "3   0.390791  78.736687   0.609304     200.0\n",
       "4   0.010653   0.043072   0.168996     200.0\n",
       "5  52.519608  96.616983  50.039494     300.0\n",
       "6   6.596059  41.218093   0.309517     300.0\n",
       "7   3.611539  48.109752  94.421756     300.0\n",
       "8  99.639696  99.051291  98.386800     300.0\n",
       "9   0.029453   0.046560   2.237074     200.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csv[['pAD_xr', 'pAD_yr', 'pAD_yf', 'pat_dx_1']].mean())\n",
    "csv[['pAD_xr', 'pAD_yr', 'pAD_yf', 'pat_dx_1']].head(10)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(csv_in, col, t, metric):\n",
    "\n",
    "    true_pos = ((csv_in[col] > t) & (csv_in.pat_dx_1 == 3)).sum()\n",
    "    true_neg = ((csv_in[col] <= t) & (csv_in.pat_dx_1 == 2)).sum()\n",
    "    false_pos = ((csv_in[col] > t) & (csv_in.pat_dx_1 == 2)).sum()\n",
    "    false_neg = ((csv_in[col] <= t) & (csv_in.pat_dx_1 == 3)).sum()\n",
    "    \n",
    "    true = true_pos + true_neg\n",
    "    false = false_pos + false_neg\n",
    "\n",
    "    if metric == 'f1':\n",
    "        prec = true_pos / (true_pos + false_pos)\n",
    "        reca = true_pos / (true_pos + false_neg)\n",
    "\n",
    "        f1_score = 2 * (prec * reca) / (prec + reca)\n",
    "        m = f1_score\n",
    "        \n",
    "    elif metric == 'acc':\n",
    "        acc_p = true_pos / (true_pos + false_neg)\n",
    "        acc_s = true_neg / (true_neg + false_pos)\n",
    "\n",
    "        balanced_acc = (acc_p + acc_s) / 2\n",
    "        m = balanced_acc\n",
    "    \n",
    "    return (round(m, 3), true, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(csv_in, col, metric):\n",
    "    l = []\n",
    "    \n",
    "    for t in np.arange(0, 1, 0.01):\n",
    "        m = get_metric(csv_in, col, t, metric)\n",
    "        l.append((*m, t))\n",
    "        \n",
    "    return (max(l)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_metric(csv_in, col, cv_split, metric):\n",
    "    \n",
    "    csv_split = csv_in[csv_in.cv_split == cv_split]\n",
    "    csv_other = csv_in[csv_in.cv_split != cv_split]\n",
    "    \n",
    "    t = get_best_threshold(csv_other, col, metric)\n",
    "    \n",
    "    m = get_metric(csv_split, col, t, metric)\n",
    "    print('split {}: {}, t={}'.format(cv_split, m, t))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_metric(csv_in, col, metric):\n",
    "    l = [get_split_metric(csv_in, col, s, metric)[0] for s in range(5)]\n",
    "    return np.array(l).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 folds with equal number of pMCI/sMCI samples each\n",
    "csv = csv.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "pMCI = csv[csv.pat_dx_1 == 3].img_id_0.values\n",
    "sMCI = csv[csv.pat_dx_1 == 2].img_id_0.values\n",
    "\n",
    "p_bins = np.linspace(0, len(pMCI), 6).astype(int)[1:-1]\n",
    "s_bins = np.linspace(0, len(sMCI), 6).astype(int)[1:-1]\n",
    "\n",
    "p_splits = np.split(pMCI, p_bins)\n",
    "s_splits = np.split(sMCI, s_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write folds to csv\n",
    "for i, (p_split, s_split) in enumerate(zip(p_splits, s_splits)):\n",
    "    csv.loc[csv.img_id_0.isin(p_split), 'cv_split'] = i\n",
    "    csv.loc[csv.img_id_0.isin(s_split), 'cv_split'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0: (0.636, 37, 16), t=0.12\n",
      "split 1: (0.615, 40, 15), t=0.12\n",
      "split 2: (0.45, 31, 22), t=0.12\n",
      "split 3: (0.609, 37, 18), t=0.14\n",
      "split 4: (0.533, 34, 21), t=0.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5685999999999999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cv_metric(csv, 'pAD_xr', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0: (0.7, 41, 12), t=0.65\n",
      "split 1: (0.64, 37, 18), t=0.59\n",
      "split 2: (0.68, 37, 16), t=0.31\n",
      "split 3: (0.634, 40, 15), t=0.77\n",
      "split 4: (0.444, 30, 25), t=0.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6195999999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cv_metric(csv, 'pAD_yr', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0: (0.529, 21, 32), t=0.03\n",
      "split 1: (0.54, 26, 29), t=0.06\n",
      "split 2: (0.542, 26, 27), t=0.15\n",
      "split 3: (0.567, 26, 29), t=0.03\n",
      "split 4: (0.525, 26, 29), t=0.18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5406"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cv_metric(csv, 'pAD_yf', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0: (0.707, 37, 16), t=0.12\n",
      "split 1: (0.7, 40, 15), t=0.14\n",
      "split 2: (0.56, 31, 22), t=0.14\n",
      "split 3: (0.679, 37, 18), t=0.14\n",
      "split 4: (0.604, 34, 21), t=0.19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cv_metric(csv, 'pAD_xr', 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0: (0.765, 41, 12), t=0.73\n",
      "split 1: (0.7, 37, 18), t=0.59\n",
      "split 2: (0.759, 39, 14), t=0.65\n",
      "split 3: (0.711, 40, 15), t=0.77\n",
      "split 4: (0.536, 30, 25), t=0.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6941999999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cv_metric(csv, 'pAD_yr', 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0: (0.607, 31, 22), t=0.71\n",
      "split 1: (0.614, 37, 18), t=0.96\n",
      "split 2: (0.57, 34, 19), t=0.96\n",
      "split 3: (0.696, 42, 13), t=0.96\n",
      "split 4: (0.55, 34, 21), t=0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6073999999999999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cv_metric(csv, 'pAD_yf', 'acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
