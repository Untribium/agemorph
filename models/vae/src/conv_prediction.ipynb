{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img[:, 40, :], cmap='gray')\n",
    "    \n",
    "def load_nii(path):\n",
    "    nii = nib.load(path)\n",
    "    vol = nii.get_data().astype(np.float32)\n",
    "    return np.squeeze(vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b1c1998e757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../runs/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrun_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'found {} runs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "run_dirs = glob.glob('../runs/*')\n",
    "run_dirs = sorted(run_dirs)\n",
    "\n",
    "print('found {} runs'.format(len(run_dirs)), '\\n')\n",
    "\n",
    "for i, run in enumerate(run_dirs):\n",
    "    print(i, run, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 600\n"
     ]
    }
   ],
   "source": [
    "# set run dir\n",
    "run_dir = run_dirs[0]\n",
    "\n",
    "pre_dirs = glob.glob(os.path.join(glob.escape(run_dir), 'test', '*'))\n",
    "pre_dirs = sorted(pre_dirs)\n",
    "\n",
    "for i, pre_dir in enumerate(pre_dirs):\n",
    "    print(i, os.path.basename(pre_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 36)\n"
     ]
    }
   ],
   "source": [
    "# generator config, run_dir, etc...\n",
    "pre_dir = pre_dirs[0]\n",
    "\n",
    "csv_path = os.path.join(pre_dir, 'meta.csv')\n",
    "csv = pd.read_csv(csv_path)\n",
    "print(csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found model file\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "run_dir = '../../../../backup/agemorph/models/clf/clf_20190330_1549_gpu=4_bs=8_lr=0.001_b1=0.9_b2=0.999_ep=0.1_bn=True_ds=1_lw=[1.0]/'\n",
    "model_name = 'clf_500'\n",
    "model_file = os.path.join(run_dir, model_name+'.h5')\n",
    "\n",
    "if os.path.isfile(model_file):\n",
    "    print('found model file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu config\n",
    "gpu_id = 7\n",
    "\n",
    "if gpu_id is not None:                                                     \n",
    "    gpu = '/gpu:' + str(gpu_id)                                            \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)                       \n",
    "    config = tf.ConfigProto()                                              \n",
    "    config.gpu_options.allow_growth = True                                 \n",
    "    config.allow_soft_placement = True                                     \n",
    "    set_session(tf.Session(config=config))                                 \n",
    "else:                                                                      \n",
    "    gpu = '/cpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting predict\n",
      "step 0\n",
      "step 10\n",
      "step 20\n",
      "step 30\n",
      "step 40\n",
      "step 50\n",
      "step 60\n",
      "step 70\n",
      "step 80\n",
      "step 90\n",
      "step 100\n",
      "step 110\n",
      "step 120\n",
      "step 130\n",
      "step 140\n",
      "step 150\n",
      "step 160\n",
      "step 170\n",
      "step 180\n",
      "step 190\n",
      "step 200\n",
      "step 210\n",
      "step 220\n",
      "step 230\n",
      "step 240\n",
      "step 250\n",
      "step 260\n",
      "step 270\n",
      "finished predict\n",
      "writing csv to ../runs/vae_20190417_1843_gpu=6_bs=4_enc=[16_32_32_32]_dec=[32_32_32_32_16_8]_lr=0.0001_pl=100_is=0.01_vr=1.0_lw=[1_1]_tag=brains_test/test/600/clf_500.csv\n"
     ]
    }
   ],
   "source": [
    "print('starting predict')\n",
    "\n",
    "with tf.device(gpu):\n",
    "    \n",
    "    # load classifier model\n",
    "    classifier = keras.models.load_model(model_file)\n",
    "    \n",
    "    for i, (_, row) in enumerate(csv.iterrows()):\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('step', i)\n",
    "        \n",
    "        xr = load_nii(row['img_path_0'])[None, ..., None]\n",
    "        yr = load_nii(row['img_path_1'])[None, ..., None]\n",
    "        yf = load_nii(row['img_path_yf'])[None, ..., None]\n",
    "        \n",
    "        batch = np.concatenate([xr, yr, yf], axis=0)\n",
    "        \n",
    "        pred = classifier.predict([batch])\n",
    "        \n",
    "        csv.loc[csv.img_id_0 == row['img_id_0'], 'pAD_xr'] = pred[0, 1]\n",
    "        csv.loc[csv.img_id_0 == row['img_id_0'], 'pAD_yr'] = pred[1, 1]\n",
    "        csv.loc[csv.img_id_0 == row['img_id_0'], 'pAD_yf'] = pred[2, 1]\n",
    "        \n",
    "print('finished predict')\n",
    "\n",
    "csv_out_path = os.path.join(pre_dir, model_name+'.csv')\n",
    "\n",
    "print('writing csv to {}'.format(csv_out_path))\n",
    "\n",
    "csv.to_csv(csv_out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 clf_200.csv\n",
      "1 clf_500.csv\n"
     ]
    }
   ],
   "source": [
    "clf_outs = glob.glob(os.path.join(glob.escape(pre_dir), '[!meta]*.csv'))\n",
    "clf_outs = sorted(clf_outs)\n",
    "\n",
    "for i, clf_out in enumerate(clf_outs):\n",
    "    print(i, os.path.basename(clf_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 39)\n"
     ]
    }
   ],
   "source": [
    "csv_path = clf_outs[1]\n",
    "csv = pd.read_csv(csv_path)\n",
    "print(csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "pMCI = csv[csv.pat_dx_1 == 3].img_id_0.values\n",
    "sMCI = csv[csv.pat_dx_1 == 2].img_id_0.values\n",
    "\n",
    "p_splits = np.split(pMCI, np.linspace(0, len(pMCI), 6).astype(int)[1:-1])\n",
    "s_splits = np.split(sMCI, np.linspace(0, len(sMCI), 6).astype(int)[1:-1])\n",
    "\n",
    "for i, (p_split, s_split) in enumerate(zip(p_splits, s_splits)):\n",
    "    csv.loc[csv.img_id_0.isin(p_split), 'cv_split'] = i\n",
    "    csv.loc[csv.img_id_0.isin(s_split), 'cv_split'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def acc_threshold(csv, col, t):\n",
    "    true_pos = ((csv[col] > t) & (csv.pat_dx_1 == 3)).sum()\n",
    "    true_neg = ((csv[col] <= t) & (csv.pat_dx_1 == 2)).sum()\n",
    "    false_pos = ((csv[col] > t) & (csv.pat_dx_1 == 2)).sum()\n",
    "    false_neg = ((csv[col] <= t) & (csv.pat_dx_1 == 3)).sum()\n",
    "\n",
    "    acc_p = true_pos / (true_pos + false_neg)\n",
    "    acc_s = true_neg / (true_neg + false_pos)\n",
    "\n",
    "    balanced_acc = (acc_p + acc_s) / 2\n",
    "\n",
    "    true = true_pos + true_neg\n",
    "    false = false_pos + false_neg\n",
    "    \n",
    "    return (round(balanced_acc, 3), true, false, round(acc_p, 2), round(acc_s, 2), round(t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_threshold(csv, col):\n",
    "    l = []\n",
    "    \n",
    "    for t in np.arange(0, 1, 0.01):\n",
    "        l.append(acc_threshold(csv, col, t))\n",
    "        \n",
    "    return max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def acc_cv(csv_in, col, cv_split):\n",
    "    \n",
    "    csv = csv_in[csv_in.cv_split != cv_split]\n",
    "    \n",
    "    t = best_threshold(csv, col)[5]\n",
    "    print(t)\n",
    "    \n",
    "    csv = csv_in[csv_in.cv_split == cv_split]\n",
    "    \n",
    "    acc = acc_threshold(csv, col, t)\n",
    "    print(acc)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "(0.615, 30, 23, 0.79, 0.44, 0.02)\n",
      "0.9\n",
      "(0.593, 37, 18, 0.3, 0.89, 0.9)\n",
      "0.41\n",
      "(0.713, 39, 14, 0.63, 0.79, 0.41)\n",
      "0.14\n",
      "(0.604, 34, 21, 0.55, 0.66, 0.14)\n",
      "0.9\n",
      "(0.639, 38, 17, 0.45, 0.83, 0.9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6327999999999999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [acc_cv(csv, 'pAD_yf', i) for i in range(5)]\n",
    "\n",
    "np.array(list(zip(*l))[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "(0.666, 35, 18, 0.68, 0.65, 0.01)\n",
      "0.02\n",
      "(0.654, 39, 16, 0.45, 0.86, 0.02)\n",
      "0.01\n",
      "(0.654, 35, 18, 0.63, 0.68, 0.01)\n",
      "0.01\n",
      "(0.582, 34, 21, 0.45, 0.71, 0.01)\n",
      "0.01\n",
      "(0.668, 37, 18, 0.65, 0.69, 0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6448"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [acc_cv(csv, 'pAD_xr', i) for i in range(5)]\n",
    "\n",
    "np.array(list(zip(*l))[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "(0.709, 34, 19, 0.95, 0.47, 0.01)\n",
      "0.01\n",
      "(0.657, 34, 21, 0.8, 0.51, 0.01)\n",
      "0.47\n",
      "(0.777, 41, 12, 0.79, 0.76, 0.47)\n",
      "0.01\n",
      "(0.789, 41, 14, 0.95, 0.63, 0.01)\n",
      "0.92\n",
      "(0.575, 35, 20, 0.35, 0.8, 0.92)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7014000000000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [acc_cv(csv, 'pAD_yr', i) for i in range(5)]\n",
    "\n",
    "np.array(list(zip(*l))[0]).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
